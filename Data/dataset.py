import os
import torch
import glob
from torch.utils.data import Dataset
from tqdm import tqdm  # Ä°lerleme Ã§ubuÄŸu iÃ§in


class SlakhChunkedDataset(Dataset):
    def __init__(self, root_dir, split="train", sequence_length=128):
        self.root_dir = root_dir
        self.sequence_length = sequence_length
        self.hop_length = 512

        # Ä°ÅŸlenmiÅŸ .pt dosyalarÄ±nÄ± bul
        self.file_paths = sorted(glob.glob(os.path.join(root_dir, "*.pt")))

        # --- CHUNKING (ParÃ§alama) HARÄ°TASI ---
        # Her bir indeksin hangi dosyaya ve hangi baÅŸlangÄ±Ã§ noktasÄ±na
        # denk geldiÄŸini tutan liste: [(dosya_yolu, baslangic_frame), ...]
        self.chunks = []

        print(f"ğŸ“Š Dataset Ä°ndeksleniyor ({split})... LÃ¼tfen bekleyin.")

        # DosyalarÄ± tek tek aÃ§Ä±p ne kadar uzun olduklarÄ±na bakmamÄ±z lazÄ±m
        # Bu iÅŸlem __init__ aÅŸamasÄ±nda biraz vakit alabilir ama eÄŸitimde hÄ±z kazandÄ±rÄ±r.
        for path in tqdm(self.file_paths):
            try:
                # Sadece shape bilgisini almak iÃ§in map_location kullanÄ±yoruz
                # Not: PyTorch tam yÃ¼kleme yapmadan header okumayÄ± desteklemez,
                # bu yÃ¼zden dosyayÄ± yÃ¼klÃ¼yoruz.
                data = torch.load(path, map_location="cpu")
                total_frames = data["target"].shape[-1]  # Ã–rn: 2000 frame

                # ÅarkÄ±yÄ± sequence_length (128) boyutunda dilimlere bÃ¶l
                # step = sequence_length (Ã–rtÃ¼ÅŸmesiz - Non-overlapping)
                # EÄŸer Ã¶rtÃ¼ÅŸme (overlap) istersen step deÄŸerini dÃ¼ÅŸÃ¼rebilirsin (Ã¶rn: 64)
                for start_idx in range(0, total_frames, self.sequence_length):
                    self.chunks.append((path, start_idx))

            except Exception as e:
                print(f"âš ï¸ Dosya okunamadÄ± veya bozuk: {path} - {e}")

        print(
            f"âœ… Ä°ndeksleme TamamlandÄ±: Toplam {len(self.chunks)} parÃ§a (chunk) oluÅŸturuldu."
        )

    def __len__(self):
        # ArtÄ±k dosya sayÄ±sÄ± deÄŸil, toplam parÃ§a sayÄ±sÄ± dÃ¶ndÃ¼rÃ¼yoruz
        return len(self.chunks)

    def __getitem__(self, idx):
        # 1. Hangi dosya ve hangi baÅŸlangÄ±Ã§ noktasÄ± olduÄŸunu al
        path, start_frame = self.chunks[idx]

        # Hedeflenen Boyutlar
        req_frames = self.sequence_length
        req_samples = req_frames * self.hop_length

        try:
            # 2. DosyayÄ± yÃ¼kle
            data = torch.load(path)
            waveform = data["waveform"].float()  # [1, Total_Samples]
            target = data["target"].float()  # [1, 88, Total_Frames]

            # 3. Kesme (Slicing) KoordinatlarÄ±nÄ± Hesapla
            end_frame = start_frame + req_frames

            start_sample = start_frame * self.hop_length
            end_sample = end_frame * self.hop_length

            # 4. Veriyi Kes
            # Not: EÄŸer end_frame, ÅŸarkÄ±nÄ±n sonundan bÃ¼yÃ¼kse PyTorch hata vermez,
            # sadece alabildiÄŸi kadarÄ±nÄ± alÄ±r (kÄ±sa gelir).
            chunk_target = target[:, :, start_frame:end_frame]
            chunk_waveform = waveform[:, start_sample:end_sample]

            # 5. Boyut KontrolÃ¼ ve Padding (Doldurma)
            # EÄŸer ÅŸarkÄ±nÄ±n son parÃ§asÄ±ysa (kÄ±sa geldiyse), sonunu 0 ile doldur.
            current_frames = chunk_target.shape[2]
            current_samples = chunk_waveform.shape[1]

            if current_frames < req_frames:
                pad_amount = req_frames - current_frames
                chunk_target = torch.nn.functional.pad(chunk_target, (0, pad_amount))

            if current_samples < req_samples:
                pad_amount = req_samples - current_samples
                chunk_waveform = torch.nn.functional.pad(
                    chunk_waveform, (0, pad_amount)
                )

            return chunk_waveform, chunk_target

        except Exception as e:
            print(f"âš ï¸ Chunk yÃ¼kleme hatasÄ±: {path} (Idx: {start_frame}) - {e}")
            # Hata durumunda boÅŸ tensor dÃ¶ndÃ¼r
            return torch.zeros(1, req_samples), torch.zeros(1, 88, req_frames)
