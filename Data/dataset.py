import os
import torch
import glob
from torch.utils.data import Dataset
from tqdm import tqdm


class SlakhChunkedDataset(Dataset):
    def __init__(self, root_dir, file_list=None, sequence_length=128):
        """
        Args:
            root_dir (str): Verilerin bulunduÄŸu klasÃ¶r.
            file_list (list, optional): Ä°ÅŸlenecek Ã¶zel dosya listesi (.pt yollarÄ±).
                                      EÄŸer None verilirse, root_dir iÃ§indeki hepsini alÄ±r.
            sequence_length (int): Modelin zaman eksenindeki girdi boyutu.
        """
        self.root_dir = root_dir
        self.sequence_length = sequence_length
        self.hop_length = 512

        # --- MODIFICATION START ---
        # EÄŸer dÄ±ÅŸarÄ±dan Ã¶zel bir liste gelirse onu kullan, gelmezse klasÃ¶rÃ¼ tara
        if file_list is not None:
            self.file_paths = file_list
            print(f"ğŸ“‚ Ã–zel dosya listesi kullanÄ±lÄ±yor: {len(self.file_paths)} dosya.")
        else:
            self.file_paths = sorted(glob.glob(os.path.join(root_dir, "*.pt")))
            print(f"ğŸ“‚ KlasÃ¶r tarandÄ±: {len(self.file_paths)} dosya bulundu.")
        # --- MODIFICATION END ---

        # --- CHUNKING HARÄ°TASI ---
        self.chunks = []

        # EÄŸer dosya listesi boÅŸsa hata vermesin, sadece uyarsÄ±n
        if len(self.file_paths) == 0:
            print(f"âš ï¸ UYARI: '{root_dir}' konumunda hiÃ§ .pt dosyasÄ± bulunamadÄ±!")
            return

        print(f"ğŸ“Š Dataset Ä°ndeksleniyor... LÃ¼tfen bekleyin.")

        for path in tqdm(self.file_paths):
            try:
                # Sadece metadata/header okumak iÃ§in map_location kullanÄ±yoruz
                # Not: .pt dosyalarÄ±nda tÃ¼m dosyayÄ± okumadan shape almak zordur,
                # ancak bu iÅŸlem eÄŸitim Ã¶ncesi sadece 1 kez yapÄ±lÄ±r.
                data = torch.load(path, map_location="cpu")

                # Hedefin (Piano Roll) uzunluÄŸunu al: [1, 88, Time] -> Time
                total_frames = data["target"].shape[-1]

                # ÅarkÄ±yÄ± sequence_length boyutunda dilimlere bÃ¶l
                # (Non-overlapping / Ã–rtÃ¼ÅŸmesiz)
                for start_idx in range(0, total_frames, self.sequence_length):
                    self.chunks.append((path, start_idx))

            except Exception as e:
                print(f"âš ï¸ Dosya okunamadÄ± veya bozuk: {path} - {e}")

        print(
            f"âœ… Ä°ndeksleme TamamlandÄ±: {len(self.file_paths)} dosyadan toplam {len(self.chunks)} parÃ§a (chunk) oluÅŸturuldu."
        )

    def __len__(self):
        return len(self.chunks)

    def __getitem__(self, idx):
        # 1. Hangi dosya ve hangi baÅŸlangÄ±Ã§ noktasÄ± olduÄŸunu al
        path, start_frame = self.chunks[idx]

        # Hedeflenen Boyutlar
        req_frames = self.sequence_length
        req_samples = req_frames * self.hop_length

        try:
            # 2. DosyayÄ± yÃ¼kle
            data = torch.load(path)
            waveform = data["waveform"].float()  # [1, Total_Samples]
            target = data["target"].float()  # [1, 88, Total_Frames]

            # 3. Kesme (Slicing) KoordinatlarÄ±nÄ± Hesapla
            end_frame = start_frame + req_frames

            start_sample = start_frame * self.hop_length
            end_sample = end_frame * self.hop_length

            # 4. Veriyi Kes
            chunk_target = target[:, :, start_frame:end_frame]

            # Waveform bazen target'tan frame hesaplamasÄ± yÃ¼zÃ¼nden birkaÃ§ sample kÄ±sa kalabilir
            # Bu yÃ¼zden gÃ¼venli slicing yapÄ±yoruz
            curr_wav_len = waveform.shape[1]
            if end_sample > curr_wav_len:
                # EÄŸer sample yetmiyorsa alabileceÄŸimizi alalÄ±m, padding aÅŸaÄŸÄ±da halledecek
                chunk_waveform = waveform[:, start_sample:]
            else:
                chunk_waveform = waveform[:, start_sample:end_sample]

            # 5. Boyut KontrolÃ¼ ve Padding (Doldurma)
            current_frames = chunk_target.shape[2]
            current_samples = chunk_waveform.shape[1]

            # Target Padding (SaÄŸ tarafa 0 ekle)
            if current_frames < req_frames:
                pad_amount = req_frames - current_frames
                chunk_target = torch.nn.functional.pad(chunk_target, (0, pad_amount))

            # Waveform Padding (SaÄŸ tarafa 0 ekle)
            if current_samples < req_samples:
                pad_amount = req_samples - current_samples
                chunk_waveform = torch.nn.functional.pad(
                    chunk_waveform, (0, pad_amount)
                )

            return chunk_waveform, chunk_target

        except Exception as e:
            print(f"âš ï¸ Chunk yÃ¼kleme hatasÄ±: {path} (Idx: {start_frame}) - {e}")
            # Hata durumunda boÅŸ tensor dÃ¶ndÃ¼r (Batch'i patlatmamak iÃ§in)
            return torch.zeros(1, req_samples), torch.zeros(1, 88, req_frames)
